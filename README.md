# Hybrid RAG E-Commerce Product Search

A hybrid Retrieval-Augmented Generation system for e-commerce product search that combines dense (embedding-based) and sparse (BM25 keyword) retrieval with a local LLM to produce grounded, explainable product recommendations.

## Architecture

```
                         USER QUERY
                    "running shoes under $150"
                             │
                             ▼
                    ┌─────────────────┐
                    │  QUERY PARSER   │
                    │  Extract price  │
                    │  constraints &  │
                    │  category hints │
                    └────────┬────────┘
                             │
              ┌──────────────┴──────────────┐
              ▼                              ▼
    ┌──────────────────┐          ┌──────────────────┐
    │ DENSE RETRIEVAL  │          │ SPARSE RETRIEVAL  │
    │ (BGE + NumPy)    │          │ (BM25)            │
    │ Top 30 by        │          │ Top 30 by keyword │
    │ semantic sim.    │          │ match             │
    └────────┬─────────┘          └─────────┬─────────┘
             │                              │
             └──────────────┬───────────────┘
                            ▼
                 ┌─────────────────────┐
                 │ RECIPROCAL RANK     │
                 │ FUSION (RRF)        │
                 │ Merge → Top 10      │
                 └──────────┬──────────┘
                            ▼
                 ┌─────────────────────┐
                 │ POST-RETRIEVAL      │
                 │ FILTERS             │
                 │ Price & category    │
                 │ constraints → Top 5 │
                 └──────────┬──────────┘
                            ▼
                 ┌─────────────────────┐
                 │ RESPONSE BUILDER    │
                 │ Product cards:      │
                 │   PROGRAMMATIC      │
                 │ Explanations:       │
                 │   LOCAL LLM         │
                 └──────────┬──────────┘
                            ▼
                      GROUNDED OUTPUT
```

## Why Hybrid Retrieval?

E-commerce search queries contain both **semantic intent** and **specific keywords**, and a single retrieval method can't handle both well:

| Query Type | Dense (Embeddings) | Sparse (BM25) |
|---|---|---|
| "comfortable headphones for long flights" | Excellent — captures semantic meaning | Poor — no exact keyword overlap with "noise-canceling over-ear" |
| "Sony WH-1000XM5" | Poor — model numbers aren't semantically meaningful | Excellent — exact keyword match |
| "affordable running shoes for women" | Good — understands intent | Good — matches "running shoes" |

By combining both with **Reciprocal Rank Fusion (RRF)**, the system gets the best of both worlds. Products that rank highly in *either* method surface to the top, and products that rank well in *both* get the strongest boost.

### Fusion Strategy: Reciprocal Rank Fusion (RRF)

RRF is rank-based, not score-based, which solves the problem of dense and sparse scores being on incompatible scales (cosine similarity 0–1 vs BM25 scores 0–30+).

```
RRF_score(product) = 1/(k + rank_dense) + 1/(k + rank_sparse)
```

Where `k=60` is the standard smoothing constant. A product ranked #1 by both methods gets the maximum boost. A product ranked #1 by one but absent from the other still scores reasonably.

### Grounding Design

To prevent LLM hallucination, the response is split into two layers:

- **Programmatic** (guaranteed accurate): Product title, price, URL, and category are pulled directly from the catalog — never generated by the LLM.
- **LLM-generated** (constrained): The model only writes a one-sentence "why it matches" explanation per product, with strict instructions to reference only provided data.

## Tech Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| Dense Retrieval | `BAAI/bge-small-en-v1.5` + NumPy | High-quality embeddings; cosine similarity via dot product on normalized vectors |
| Sparse Retrieval | BM25 via `rank-bm25` | Standard keyword retrieval, handles brand names and exact terms |
| Fusion | Reciprocal Rank Fusion | Rank-based — avoids score normalization issues |
| LLM | Local model via LM Studio (OpenAI-compatible API) | Free, local, no API keys; portable via `openai` SDK |
| Dataset | McAuley-Lab/Amazon-Reviews-2023 | Real Amazon ASINs for verifiable URLs, rich product metadata |
| CLI | `typer` + `rich` | Clean interface with progress bars and formatted output |

## Setup

### Prerequisites

- Python 3.10+
- [LM Studio](https://lmstudio.ai/) installed with a model loaded and server started (default: `http://localhost:1234`)

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/hybrid-rag-ecommerce.git
cd hybrid-rag-ecommerce

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Download Data & Build Indices

```bash
python scripts/setup_data.py
```

This will:
1. Download ~5,000 products from 4 Amazon categories via HuggingFace
2. Preprocess and save to `data/products.json`
3. Build the ChromaDB vector index (dense)
4. Build the BM25 index (sparse)

First run takes a few minutes (downloading data + encoding embeddings).

## Usage

### Single Query

```bash
python scripts/search.py "affordable running shoes for women"
```

### With Options

```bash
# Limit to 3 results
python scripts/search.py "lightweight laptop under 1000" --top-k 3

# Retrieval only (no LLM) — useful for debugging
python scripts/search.py "wireless headphones" --no-llm
```

### Interactive Mode

```bash
python scripts/search.py --interactive
```

### Example Queries

```
"affordable running shoes for women"
"lightweight laptop under $1,000"
"Sony noise canceling headphones"
"kitchen appliances between $50 and $200"
"yoga mat for beginners"
"USB-C charger"
```

## Data

**Source:** [McAuley-Lab/Amazon-Reviews-2023](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023) on HuggingFace.

**Categories:** Electronics, Clothing Shoes & Jewelry, Sports & Outdoors, Home & Kitchen.

**Preprocessing:**
- Filter out products missing title, price, or both description and features
- Parse price strings to floats (handle `$`, ranges, commas)
- Deduplicate by Amazon parent ASIN
- Sample ~1,250 products per category for a balanced catalog
- URLs constructed from real ASINs: `https://www.amazon.com/dp/{ASIN}`

All product URLs are real, verifiable Amazon links derived from the dataset's ASINs.

## Running Tests

```bash
pytest tests/ -v
```

Tests cover:
- Query parser (price extraction, category hints, edge cases)
- BM25 tokenization (hyphenated terms, model numbers)
- RRF fusion (overlap boosting, empty lists, top-k limiting)
- Data loader (price parsing, field joining)
- LLM response parsing (valid, partial, malformed responses)

## Limitations & Future Improvements

**Current Limitations:**
- Category hint extraction uses simple keyword matching — a classifier would be more robust
- BM25 tokenizer is basic — no stemming or synonym expansion
- Price extraction relies on regex patterns — won't catch all natural language price expressions
- LLM explanations depend on LM Studio being available (falls back to generic text if not)
- Product catalog is a static snapshot — no real-time inventory or pricing

**Potential Improvements:**
- **Re-ranking:** Add a cross-encoder re-ranker between RRF fusion and final output for better precision
- **Query expansion:** Use the LLM to expand queries with synonyms before retrieval
- **Weighted fusion:** Allow configurable weights for dense vs sparse based on query type
- **Faceted search:** Add structured filters (brand, rating, availability) alongside free-text search
- **Streaming:** Stream LLM responses for lower perceived latency
- **Evaluation framework:** Automated relevance scoring with labeled query-product pairs

## Project Structure

```
hybrid-rag-ecommerce/
├── README.md               # This file
├── requirements.txt        # Python dependencies
├── config.yaml             # All configurable parameters
├── .gitignore
├── data/
│   └── .gitkeep            # products.json created by setup_data.py
├── src/
│   ├── __init__.py
│   ├── config.py           # Config loader with defaults
│   ├── data_loader.py      # Download, preprocess, load products
│   ├── retrieval.py        # Dense + Sparse retrievers + RRF fusion
│   ├── query_parser.py     # Extract price/category from queries
│   ├── llm.py              # LM Studio client + prompt templates
│   └── pipeline.py         # End-to-end orchestration
├── scripts/
│   ├── setup_data.py       # One-command data download + indexing
│   └── search.py           # CLI for search (single, interactive)
└── tests/
    ├── __init__.py
    ├── test_retrieval.py    # Unit tests for retrieval components
    └── test_pipeline.py     # Tests for data loading + LLM parsing
```
